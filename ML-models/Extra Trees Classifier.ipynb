{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding in our libraries and data file\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "survival_df = pd.read_csv(\"../Resources/cleaned_data_survival_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee146507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling our X variable to drop our target variable\n",
    "#setting our y variable to be our target variable\n",
    "X = survival_df.drop('hospital_death', axis=1)\n",
    "y = survival_df['hospital_death']\n",
    "\n",
    "#dummy-coding the rest of our X categorical variables\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54078194",
   "metadata": {},
   "source": [
    "### Balance the data set - OVERsampling\n",
    "\n",
    "#### Since our data was not evenly distributed, we decided to use a method called OVERsampling to help compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance Data - oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Original dataset shape', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_ros))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#Splitting our data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, random_state=45)\n",
    "\n",
    "#Running ExtraTreesClassifer\n",
    "clf = ExtraTreesClassifier(random_state=45, n_estimators=50).fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing our model\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Test Acc: %.3f' % clf.score(X_test, y_test))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862096c",
   "metadata": {},
   "source": [
    "### Since there is a large amount of features, we want to see which features are the most important. Below we are running feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eae2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,200)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05665b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here are our top 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11701d1",
   "metadata": {},
   "source": [
    "### Evaluating Top 10 Features\n",
    "\n",
    "1. ICU death probability\n",
    "2. Ventilation\n",
    "3. Glascow Coma Scale (GCS) verbal score\n",
    "4. GCS eyes score\n",
    "5. Hospital death probability\n",
    "6. GCS motor score\n",
    "7. Day 1 minimum systolic blood pressure (BP), noninvasive\n",
    "8. Day 1 minimum systolic blood pressure\n",
    "9. Age\n",
    "10. Minimum mean blood pressure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_df_features = survival_df[['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', 'd1_sysbp_noninvasive_min',\n",
    "                                  'd1_sysbp_min', 'age', 'd1_mbp_noninvasive_min', 'gcs_motor_apache', 'ventilated_apache',\n",
    "                                  'gcs_verbal_apache', 'gcs_eyes_apache','hospital_death']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332002ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = survival_df_features.drop('hospital_death', axis=1)\n",
    "y = survival_df_features['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance Data - oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Original dataset shape', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, random_state=45)\n",
    "\n",
    "clf = ExtraTreesClassifier(random_state=45, n_estimators=50).fit(X_train, y_train)\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(clf, 'model_ExtraTrees.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927a4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData38] *",
   "language": "python",
   "name": "conda-env-PythonData38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
